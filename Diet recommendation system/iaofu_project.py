# -*- coding: utf-8 -*-
"""IAOFU Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1keIMw_KHniJe2rpToy-S7_cW1Xvu2bzL

# Imports and environment setup
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow
!pip install visualkeras

"""# Data Preprocessing

"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score
import tensorflow as tf
from tensorflow.keras.utils import plot_model
import numpy as np
import joblib

# Load and preprocess the dataset
file_path = "drive/MyDrive/Pacienti ML.xlsx"
df = pd.read_excel(file_path)

print(df)

# Encode meal columns
meal_columns = ['BREAKFAST', 'LUNCH', 'DINNER']
encoders = {col: LabelEncoder() for col in meal_columns}
for col in meal_columns:
    df[col] = encoders[col].fit_transform(df[col])

# Encode categorical variables
df['GENDER'] = LabelEncoder().fit_transform(df['GENDER'])
categorical_features = ['SMOKER', 'CHRONIC KIDNEY DISEASE', 'ISCHEMIC HEART DISEASE',
                        'HYPERTENSION', 'DIABETES']
df[categorical_features] = df[categorical_features].astype(int)

# Normalize numerical features
numerical_features = ['AGE', 'BMI', 'HEIGHT', 'WEIGHT', 'SYSTOLIC BLOOD PRESSURE',
                      'DIASTOLIC BLOOD PRESSURE', 'GLUCOSE', 'GLYCOSYLATED HEMOGLOBIN',
                      'TOTAL CHOLESTEROL', 'TRIGLYCERIDES', 'eGFR']
scaler = StandardScaler()
df[numerical_features] = scaler.fit_transform(df[numerical_features])


df['RATING'] = df['RATING'] / 100.0

# Define features and target variables
patient_features = ['AGE', 'GENDER', 'BMI', 'HEIGHT', 'WEIGHT', 'SYSTOLIC BLOOD PRESSURE',
                    'DIASTOLIC BLOOD PRESSURE', 'GLUCOSE', 'GLYCOSYLATED HEMOGLOBIN',
                    'TOTAL CHOLESTEROL', 'TRIGLYCERIDES', 'eGFR', 'SMOKER',
                    'CHRONIC KIDNEY DISEASE', 'ISCHEMIC HEART DISEASE', 'HYPERTENSION', 'DIABETES']

patient_features_with_score = ['AGE', 'GENDER', 'BMI', 'HEIGHT', 'WEIGHT', 'SYSTOLIC BLOOD PRESSURE',
                    'DIASTOLIC BLOOD PRESSURE', 'GLUCOSE', 'GLYCOSYLATED HEMOGLOBIN',
                    'TOTAL CHOLESTEROL', 'TRIGLYCERIDES', 'eGFR', 'SMOKER',
                    'CHRONIC KIDNEY DISEASE', 'ISCHEMIC HEART DISEASE', 'HYPERTENSION', 'DIABETES', 'RATING']

# Split the dataset into training, validation, and testing sets by patient
df_train, df_temp = train_test_split(df, test_size=0.2, random_state=42)
df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)

# Keep meals and patients df from whole dataset
meals = df[meal_columns].stack().reset_index(level=1).rename(columns={"level_1": "MealType", 0: "Meal"})
patients = df[patient_features_with_score].iloc[meals.index]

# Function to stack meals for a given subset
def stack_meals(df_subset):
    """
    Stack meals for a given subset and return the patient features and corresponding meals.
    Args:
        df_subset (pd.DataFrame): Subset of the original dataset.

    Returns:
        patients (pd.DataFrame): Patient features repeated for each meal.
        meals (pd.DataFrame): Stacked meal recommendations with MealType and Meal columns.
    """
    # Reset index to ensure alignment
    df_subset = df_subset.reset_index(drop=True)

    # Stack meal recommendations
    meals = df_subset[meal_columns].stack().reset_index(level=1).rename(columns={"level_1": "MealType", 0: "Meal"})

    # Align patient features with stacked meals
    patients = df_subset[patient_features_with_score].iloc[meals.index].reset_index(drop=True)
    meals = meals.reset_index(drop=True)

    return patients, meals

# Process meals for each subset
X_train, y_train = stack_meals(df_train)
X_val, y_val = stack_meals(df_val)
X_test, y_test = stack_meals(df_test)

# Prepare input arrays
meal_input_train = y_train['Meal'].values.reshape(-1, 1)
meal_input_val = y_val['Meal'].values.reshape(-1, 1)
meal_input_test = y_test['Meal'].values.reshape(-1, 1)

train_scores = X_train["RATING"]
val_scores = X_val["RATING"]

train_scores_array = train_scores.to_numpy().reshape(-1, 1)
val_scores_array = val_scores.to_numpy().reshape(-1, 1)

# Normalizing train_scores
train_scores_min = np.min(train_scores_array)
train_scores_max = np.max(train_scores_array)
normalized_train_scores = (train_scores_array - train_scores_min) / (train_scores_max - train_scores_min)

# Normalizing val_scores
val_scores_min = np.min(val_scores_array)
val_scores_max = np.max(val_scores_array)
normalized_val_scores = (val_scores_array - val_scores_min) / (val_scores_max - val_scores_min)

patient_input_train = X_train.drop("RATING", axis=1).values
patient_input_val = X_val.drop("RATING", axis=1).values
patient_input_test = X_test.drop("RATING", axis=1).values


joblib.dump(scaler, 'scaler.pkl')
joblib.dump(encoders, 'encoder.pkl')

print(patient_input_train)
print(patient_input_train.shape)
print(meal_input_train)
print(meal_input_train.shape)
print(train_scores_array)
print(train_scores_array.shape)

print(np.isnan(patient_input_train).any(), np.isinf(patient_input_train).any())
print(np.isnan(meal_input_train).any(), np.isinf(meal_input_train).any())
print(np.isnan(train_scores_array).any(), np.isinf(train_scores_array).any())

patient_input_train = np.nan_to_num(patient_input_train)

print(np.isnan(patient_input_train).any(), np.isinf(patient_input_train).any())

np.argwhere(np.isnan(patient_input_train))

"""# Model architecture and training"""

# Build the Neural Collaborative Filtering Model
def build_ncf_model(num_patients, num_meals, embedding_size=50, dropout_rate=0.2):
    # Patient input and dense layer
    patient_input = tf.keras.layers.Input(shape=(len(patient_features),), name="PatientInput")
    patient_dense = tf.keras.layers.Dense(embedding_size, activation="relu")(patient_input)
    patient_dense = tf.keras.layers.Dropout(dropout_rate)(patient_dense)  # Add dropout here

    # Meal input and embedding layer
    meal_input = tf.keras.layers.Input(shape=(1,), name="MealInput")
    meal_embedding = tf.keras.layers.Embedding(num_meals, embedding_size)(meal_input)
    meal_flatten = tf.keras.layers.Flatten()(meal_embedding)

    # Matrix factorization output
    mf_output = tf.keras.layers.Dot(axes=1)([patient_dense, meal_flatten])

    # Concatenation for MLP path
    concatenated = tf.keras.layers.Concatenate()([patient_dense, meal_flatten])
    mlp_output = tf.keras.layers.Dense(128, activation="relu")(concatenated)
    mlp_output = tf.keras.layers.Dropout(dropout_rate)(mlp_output)  # Add dropout here
    mlp_output = tf.keras.layers.Dense(64, activation="relu")(mlp_output)
    mlp_output = tf.keras.layers.Dropout(dropout_rate)(mlp_output)  # Add dropout here
    mlp_output = tf.keras.layers.Dense(32, activation="relu")(mlp_output)

    # Combine matrix factorization and MLP paths
    combined = tf.keras.layers.Concatenate()([mf_output, mlp_output])
    output = tf.keras.layers.Dense(1, activation="sigmoid")(combined)

    # Compile the model
    model = tf.keras.models.Model(inputs=[patient_input, meal_input], outputs=output)
    model.compile(optimizer="adam", loss="mse", metrics=["accuracy"])

    return model

# Instantiate the model
num_meals = meals['Meal'].nunique()
model = build_ncf_model(len(patients), num_meals)

plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)

# Save the best model during training
checkpoint = tf.keras.callbacks.ModelCheckpoint(
    'best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)

# Train the model with validation
history = model.fit(
    [patient_input_train, meal_input_train],
    train_scores_array,  # Placeholder labels
    validation_data=([patient_input_val, meal_input_val], val_scores_array),
    epochs=100,
    batch_size=64,
    callbacks=[checkpoint],
    verbose=1,
)

"""# Performance evaluation"""

from sklearn.metrics import accuracy_score, precision_score, recall_score

def evaluate_top_k(model, patient_input_test, meal_input_test, y_test, encoders, k=5):
    """
    Evaluate the model's recommendations using Top-k accuracy, precision, and recall.

    Args:
        model (tf.keras.Model): Trained model.
        patient_input_test (np.ndarray): Test patient features.
        meal_input_test (np.ndarray): All meal indices for the test set.
        y_test (pd.DataFrame): Ground truth DataFrame containing MealType and Meal.
        encoders (dict): Encoders for decoding meal indices.
        k (int): Number of top recommendations to consider.

    Returns:
        top_k_accuracy (float): Top-k accuracy of the model.
        precision_at_k (float): Precision at k.
        recall_at_k (float): Recall at k.
    """
    total_matches = 0
    total_relevant = len(y_test)
    total_recommended = 0

    for i, patient in enumerate(patient_input_test):
        ground_truth_meal = y_test.iloc[i]["Meal"]
        meal_type = y_test.iloc[i]["MealType"]

        # Predict compatibility scores for all meals
        all_meals = np.arange(len(encoders[meal_type].classes_)).reshape(-1, 1)
        patient_repeated = np.tile(patient, (len(all_meals), 1))
        compatibility_scores = model.predict([patient_repeated, all_meals], verbose=0).flatten()

        # Get top-k meal indices
        top_k_meal_indices = compatibility_scores.argsort()[::-1][:k]

        # Check if the ground truth is in the top-k
        if ground_truth_meal in top_k_meal_indices:
            total_matches += 1

        total_recommended += len(top_k_meal_indices)

    # Metrics
    top_k_accuracy = total_matches / total_relevant
    precision_at_k = total_matches / total_recommended
    recall_at_k = total_matches / total_relevant

    return top_k_accuracy, precision_at_k, recall_at_k


k = 20
# Evaluate the model
top_k_accuracy, precision_at_k, recall_at_k = evaluate_top_k(
    model, patient_input_test, meal_input_test, y_test, encoders, k=k
)

print(f"Top-{k} Accuracy: {top_k_accuracy:.2f}")
print(f"Precision at {k}: {precision_at_k:.2f}")
print(f"Recall at {k}: {recall_at_k:.2f}")

"""# Test examples visualization"""

# Load the best model
model.load_weights('best_model.keras')

def display_full_test_results(patients, model, meal_encoders, y_test, meal_columns, top_n=5):
    """
    Display medical profiles, predicted meals, and ground truth meals for all patients in the test set.

    Args:
        patients (np.ndarray): Test patient profiles (scaled).
        model (tf.keras.Model): Trained NCF model.
        meal_encoders (dict): Encoders to decode meal indices into names.
        y_test (pd.DataFrame): Ground truth meal indices with MealType included.
        meal_columns (list): List of meal types (e.g., ['BREAKFAST', 'LUNCH', 'DINNER']).
        top_n (int): Number of top recommendations to display.
    """
    print("\n--- Full Test Results ---\n")

    for i, patient in enumerate(patients):
        if i % 3 == 0:
            print(f"Patient {i // 3 + 1}'s Medical Profile:")
            for feature, value in zip(patient_features, patient):
                print(f"  {feature}: {value}")

            print("\nTop Predicted Diet Plans:")
            for meal_type in meal_columns:  # ['BREAKFAST', 'LUNCH', 'DINNER']
                # Generate compatibility scores for all meals of the current type
                all_meals = np.arange(len(encoders[meal_type].classes_)).reshape(-1, 1)
                patient_input = np.tile(patient, (len(all_meals), 1))
                compatibility_scores = model.predict([patient_input, all_meals], verbose=0).flatten()

                # Rank meals by compatibility
                recommended_meals = compatibility_scores.argsort()[::-1][:top_n]

                # Decode the top predictions
                top_predicted_meals = encoders[meal_type].inverse_transform(recommended_meals)

                # Print the top recommendations
                print(f"  {meal_type}:")
                for rank, meal in enumerate(top_predicted_meals, start=1):
                    print(f"    Rank {rank}: {meal}")

            print("\nGround Truth Diet Plan:")
            for meal_type in meal_columns:
                # Filter meals for the current meal type and ensure alignment with y_test
                filtered_meals = meals[(meals["MealType"] == meal_type) & (meals.index.isin(y_test.index))]

                ground_truth_index = filtered_meals.iloc[i]["Meal"]
                ground_truth_meal = meal_encoders[meal_type].inverse_transform([ground_truth_index])[0]
                print(f"  {meal_type}: {ground_truth_meal}")

            print("\n" + "-" * 50 + "\n")


# Call the function for the test set
display_full_test_results(
    patient_input_test,  # Test patient profiles
    model,  # Trained model
    encoders,  # Meal-specific encoders
    y_test,  # Ground truth with MealType and Meal columns
    meal_columns,  # Meal types ['BREAKFAST', 'LUNCH', 'DINNER']
    top_n=5  # Display top 5 recommendations
)